{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Need bullshiting something for the start</font>\n",
    "\n",
    "In this script, we include:\n",
    "\n",
    "1. Baseline model: we adopt 'Jaccard similarity' to calculate similarity score of each pair of playlist in our dataset, and predict the tracks in similar playlists.\n",
    "\n",
    "2. Advanced models\n",
    " - <font color=red>David's model 1\n",
    " - David's model 2\n",
    " - David's model n...</font>\n",
    " - artificial neural network: we use latent vector to create a collaborative filtering neural network and use the model to predict the \"interaction\" score for user(playlist) and item(track), we include the parameter selection process and the final model fitting\n",
    "\n",
    "3. Combined model: combine baseline and advanced model together to generate the final recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import related packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from time import time\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count script running times\n",
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function: combine separate dataset and get the \n",
    "#playlists(a dictionary with key of playlist id and value of a list of tracks)\n",
    "\n",
    "#input: n is how many piece of data that will be generated(1 piece of data has 1,000 playlists)\n",
    "#       m is the starting point(eg. the 1th piece of data)\n",
    "#output: a dictionary containing users(playlists id) and track names\n",
    "\n",
    "def load_dataset(n, m):\n",
    "    c = m*1000\n",
    "    playlists = {}\n",
    "    for p in range(m, n+m):\n",
    "        start = p*1000\n",
    "        end = start+999\n",
    "        with open('data/mpd.slice.{0}-{1}.json'.format(start, end)) as f:\n",
    "            piece = json.load(f)\n",
    "            play_list = [lst['tracks'] for lst in piece['playlists']]\n",
    "            for ply in play_list:\n",
    "                track_names = [track_name['track_name'] for track_name in ply]\n",
    "                playlists[c] = track_names\n",
    "                c += 1\n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function: get the dataframe(index, user, track, interaction{1=interaction exists})\n",
    "#input: a dictionary of playlist\n",
    "#output: the cleaned dataframe\n",
    "\n",
    "def get_data(playlists):\n",
    "    users, items = [], []\n",
    "    for user in playlists:\n",
    "        for item in playlists[user]:\n",
    "            users.append(user)\n",
    "            items.append(item)\n",
    "            \n",
    "    data = pd.DataFrame(users, columns=['user'])\n",
    "    data['track'] = items\n",
    "    \n",
    "    #encoding the track names into numbers\n",
    "    data['track'] = data['track'].astype('category').cat.codes\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be two dataset to work on:\n",
    "- the first is the full dataset including 10,000 playlists(the first 10 pieces of the whole dataset), it will be used for model training and tesing.\n",
    "- the second dataset is the dataset used for model parameter optimization (cross validation to select best parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataset will be finally like:\n",
    "![baseline model](image/data_example.jpg)\n",
    "\n",
    "where \"user\" is defined as each individual playlist. The \"track\" is randomly selected tracks in the full dataset, noted that each track is encoded into numbers. The \"y\" is the interaction of the user and item(playlist). If the track exists in the playlist, the \"y\" (interaction) will be 1, otherwise it will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the size of data\n",
    "n_playlist = 10\n",
    "m_playlist = 0\n",
    "n_adjust = 1\n",
    "m_adjust = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the two dataset\n",
    "data_full = get_data(load_dataset(n_playlist, m_playlist))\n",
    "data_adjust = get_data(load_dataset(n_adjust, m_adjust))\n",
    "data_adjust.user = data_adjust.user-m_adjust*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Description**\n",
    "\n",
    "The baseline model is based on comparing each pair of “tracks” and hence computing the “similarity score” by using the 'Jaccard similarity' similarity measurement:\n",
    "![jaccard similarity](image/jaccard_similarity.jpg)\n",
    "\n",
    "The dataset we use in baseline model is the full dataset(10,000) playlist.\n",
    "\n",
    "The baseline model assumes that one user owns at least one playlist, and it computes the similarity score\n",
    "of this user playlist with each of the playlists in the dataset. The recommendation tracks will be generated from\n",
    "the playlist that has the highest similarity with the user playlist.\n",
    "\n",
    "In this model, we only include a sample dataset of 10,000 playlists from the whole dataset (1 million\n",
    "playlists). We split the sample dataset into a Playlist Bank and a Training set. The Playlist Bank contains\n",
    "90% of the data (9,000) playlists and the Training Set contains 10% of the data(1,000) playlists. For each playlist in the Training Set, we hide one track to be the track that we try to predict, and we set the rest as our predictors. For each training list, if the hidden track exist in our prediction track list, we will define the error rate of this training list to 0, otherwise, to 1. And we average the total error of 500 playlists to be our total error rate.\n",
    "\n",
    "For the final recommendation tracks, we will first get the not-overlap tracks in top 5 similary playlists, and randomly select 100 as our recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model design**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![baseline model](image/baseline_model.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into playlist bank (90%) and training set (10%)\n",
    "playlist_bank = {}\n",
    "for user in range(n_playlist*900):\n",
    "    playlist_bank[user] = list(data_full[data_full['user']==user]['track'])\n",
    "\n",
    "playlist_data = {}\n",
    "for user in range(n_playlist*900, n_playlist*1000):\n",
    "    playlist_data[user] = list(data_full[data_full['user']==user]['track'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#check out the length of playlist bank and the training set\n",
    "print(len(playlist_bank))\n",
    "print(len(playlist_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the similarity function\n",
    "#input: two list with items\n",
    "#output: the similairty score of two lists\n",
    "def cal_similarity(list_one, list_two):\n",
    "    no_overlap = list(Counter(list_one)-Counter(list_two))\n",
    "    similarity = ((len(list_one)-len(no_overlap))*2)/(len(list_one)+len(list_two))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to hide the first track in each playlist\n",
    "#input: the dictionary of playlists\n",
    "#output: a list of the hidden track and a dictionary of users and the unhidden tracks\n",
    "def hide_track(playlists):\n",
    "    track_hide = []\n",
    "    track_train = {}\n",
    "    for key in playlists:\n",
    "        track_hide.append(playlists[key][0])\n",
    "        track_train[key] = playlists[key][1:]\n",
    "    return track_hide, track_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function of getting the recommendation list\n",
    "#input: the playlists that is to be predicted\n",
    "#       the playlist bank\n",
    "#       the number of similar playlist that need to be generated\n",
    "#output: the list of recommendation tracks\n",
    "\n",
    "def get_recommendation_list(track_train, playlist_bank, no_similar_playlist):\n",
    "    recommendation_track = []\n",
    "    time_train = 0\n",
    "    for ut in track_train:\n",
    "        sim_score = np.zeros(len(playlist_bank))\n",
    "        time_bank = 0\n",
    "        for ub in playlist_bank:\n",
    "            sim_score[time_bank] = cal_similarity(track_train[ut], playlist_bank[ub])\n",
    "            time_bank += 1\n",
    "        similarity_df = pd.DataFrame(sim_score, index=range(len(sim_score)))\n",
    "        similarity_df = similarity_df.sort_values(by=0, ascending=False)\n",
    "        index = list(similarity_df.index[[x for x in range(no_similar_playlist)]])\n",
    "        sample_names = []\n",
    "        for i in index:\n",
    "            sample_names.append(playlist_bank[i])\n",
    "        recommendation_track.append([track for playlist in sample_names for track in playlist])\n",
    "        time_train += 1\n",
    "    return recommendation_track    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of hidden track and the dictionary of training tracks\n",
    "track_hide, track_train_base = hide_track(playlist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 5 similar playlists as our base of recommendation list\n",
    "#Randomly select 100 of them as our final recommendation\n",
    "recommendation_list = get_recommendation_list(track_train_base, playlist_bank, 5)\n",
    "no_recommendation = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the score of the prediction\n",
    "scores = np.zeros(len(track_train_base))\n",
    "for n in range(len(track_hide)):\n",
    "    not_overlap = list(Counter(recommendation_list[n])-Counter(track_train_base[n+900*m_adjust]))\n",
    "    np.random.shuffle(not_overlap)\n",
    "    recommendation = np.array(not_overlap)[:no_recommendation]\n",
    "    if track_hide[n] in recommendation:\n",
    "        scores[n] = 1\n",
    "score = np.mean(scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.171\n"
     ]
    }
   ],
   "source": [
    "print('The score is {0}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the score is very low of this baseline model because it has several limiations:\n",
    "\n",
    "1. Bias in calculating similarity score: although the process of finding the hidden track is supervised, the process of calculating similarity score is actually unsupervised since we don’t have an exact benchmark for “similarity of two playlists”. Therefore, the similarity score we calculated may be hesitated.\n",
    "\n",
    "2. Even though we find the top 5 similar playlists, we applied no but the random selection techque in choosing the 100 tracks as our recommendation. Other critera will be explored in advanced models.\n",
    "\n",
    "3. Too much related to the sample size: the sample is small, and it only contains 1% of the original dataset. The bigger the Playlist Bank, the higher the probability we find a “twin” of our training list.\n",
    "\n",
    "4. Predictor selection: the only predictor we use to compute the similarity is “track_name” in the playlist. However, there are more predictors in the dataset that seem to be useful, such as “album_name”, “artist_name”, “popular_artist”, “popular_album”, “playlist_name”, and so on. They will be exlored in the advanced modeling.\n",
    "\n",
    "5. Computation cost: the computation cost need to be reduced.\n",
    "\n",
    "7. Cold-start problem: since the model assumes that there is already an existing playlist for one user, it does not take the “cold-start” problem into account. This issue should be discussed in the advanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Say something for starting...</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Input Davids models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our artificial neural network is based on the research of the paper: **Neural Collaborative Filtering** https://arxiv.org/pdf/1708.05031.pdf. In this paper, the matrix factorization and lantent vector technique is applied to deal with the input of data and these two techniques will be used in the artificial neural network we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Description**\n",
    "\n",
    "We will do a little manipulation in our data to put it into a matrix: matrix shown below.\n",
    "Each row of the matrix represent the user(playlist) and each column of matrix represent the item(tracks). The value of the matrix is the \"interaction\". We mark \"1\" as the interaction of user and item exist and 0 otherwise. As illustrated before, the \"interaction\" means that the user have the item in his/her pocket.\n",
    "![Compare](image/compare.jpg)\n",
    "\n",
    "Matrix Factorization (MF) associates each user and item with a real-valued vector of latent features. It is shown below. The latent features are presented in the right handside of the above figures as compared with the matrix. As the research of **Neural Collaborative Filtering** indicated, there are some differences between \"Jaccard similarity\" and the \"matrix factorization\": in matrix, the u4 is most similar to u1, followed by u3 and u2 while in MF, the P4 is similar to P1, followed by P2 and P3 which indicated the \"ranking lost\" of MF. This could be one of the source of the model limitations.\n",
    "![MF](image/mf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Design**\n",
    "\n",
    "Our neural network aimed to estimate the function to predict the y_hat(ui). The input layer includes two dataset: the \"user\" and \"track\". The second layer is the embedding layer with user latent vector and track latent vector. And we added other layers in neural network to tune our predictions. The output layer is the predicted \"interaction\" ('y' in dataset). The prediction score is a probability ranged from 0 to 1. The probability indicated the likelyhood of the iteraction between the playlist and track. The higher the probability, the more likely that the user will like the track.\n",
    "![Neural Network Model](image/neural_network_model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting Model Parameter**\n",
    "\n",
    "There are several parameters here that we need to adjust while we could not show the process of all of it for this scope of project. Hence, we apply most of the parameters tested in previous paper and show just three of them in this project: latent_dims, learning rate, epochs.\n",
    "\n",
    "The dataset we use adjust the parameters is the data_adjust, which take the 10th piece of the original data(1000 playlists). We seperate the data into training and testing(validation) set for the ratio of 0.8 to 0.2. After adjuting the parameter, we build our final model for the optimal parameters and fit the full dataset(10,000 playlist) like we did in previous model.\n",
    "\n",
    "**About Prediction**\n",
    "\n",
    "The prediction of this model will not be a recommendation list but the likelihood of if the user will posisbly interact with each specific track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the matrix for (user, track)\n",
    "#input: a dataframe of (user, track, interaction)\n",
    "#output: the designed matrix\n",
    "def get_matrix(data, no_interaction):\n",
    "    num_user = len(data['user'].unique())\n",
    "    num_track = len(data['track'].unique())\n",
    "    data_matrix = sp.dok_matrix((num_user, num_track), dtype=np.float32)\n",
    "    for u, t in zip(data['user'], data['track']):\n",
    "        data_matrix[u, t] = 1.0\n",
    "    return num_user, num_track, data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we know, the unique tracks in all the 10,000 playlists will be huge. Hence, if we use all the tracks that exist and donnot exist in each individual user, the portion of \"not existing\" tracks will be much bigger than that of \"existing tracks\". Therefore, if we do so, our prediction will always prediction the track to \"not exist\" in the playlist and we will get a high score of 0.99999999. It doesn't make sense though.**\n",
    "\n",
    "**So the following functions is to randomly get our training data to make it include 0.5-0.5 true and false response portion in both our training and test set so that our decision boundry will be 0.5 as default in neural network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the random features\n",
    "#input: the data matrix\n",
    "#output: the desighed user, track input and response variable\n",
    "def get_features(data_matrix):\n",
    "    num_user, num_track = data_matrix.shape\n",
    "    user_data, track_data, y_data = [],[],[]\n",
    "    \n",
    "    for (u, i) in data_matrix.keys():\n",
    "        user_data.append(u)\n",
    "        track_data.append(i)\n",
    "        y_data.append(1)\n",
    "        \n",
    "        for t in range(no_interaction):\n",
    "            j = np.random.randint(num_track)\n",
    "            while (u,j) in data_matrix:\n",
    "                j = np.random.randint(num_user)\n",
    "            user_data.append(u)\n",
    "            track_data.append(j)\n",
    "            y_data.append(0)\n",
    "                \n",
    "    return user_data, track_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "def build_model(num_user, num_track, latent_dim):\n",
    "    user_train = Input(shape=(1,), dtype='int32', name = 'user_train')\n",
    "    track_train = Input(shape=(1,), dtype='int32', name = 'track_train')\n",
    "\n",
    "    MF_Embedding_user = Embedding(input_dim = num_user, output_dim = latent_dim, embeddings_initializer='uniform', embeddings_regularizer = l2([0,0][0]), input_length=1)\n",
    "    MF_Embedding_track = Embedding(input_dim = num_track, output_dim = latent_dim, embeddings_initializer='uniform', embeddings_regularizer = l2([0,0][0]), input_length=1)   \n",
    "    \n",
    "    user_latent = Flatten()(MF_Embedding_user(user_train))\n",
    "    track_latent = Flatten()(MF_Embedding_track(track_train))\n",
    "\n",
    "    predictor = add([user_latent, track_latent])\n",
    "    prediction = Dense(1, activation=\"sigmoid\", name=\"prediction\", kernel_initializer=\"lecun_uniform\")(predictor)\n",
    "    NNmodel = Model(inputs=[user_train, track_train], outputs=prediction)\n",
    "    return NNmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function to make plot for selection parameters\n",
    "def make_plot(x, y_train, y_test, name):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 5))\n",
    "    ax.plot(x, y_train, label='train')\n",
    "    ax.plot(x, y_test, label='test')\n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel('scores')\n",
    "    ax.set_title('{} Selection'.format(name))\n",
    "    ax.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get matrix\n",
    "no_interaction = 1\n",
    "num_user, num_track, matrix = get_matrix(data_adjust, no_interaction)\n",
    "user, track, y = get_features(matrix)\n",
    "data_nn = pd.DataFrame(user, columns=['user'])\n",
    "data_nn['track'] = track\n",
    "data_nn['y'] = y\n",
    "\n",
    "#get train and test data\n",
    "data_copy = data_nn.copy()\n",
    "data_test = pd.DataFrame(columns=['user', 'track', 'y'])\n",
    "for n in range(n_adjust*900, n_adjust*1000):\n",
    "    data_hide = data_copy[data_copy.user == n].iloc[0:2]\n",
    "    data_test = data_test.append(data_hide)\n",
    "    \n",
    "data_train = data_copy.drop(data_test.index)\n",
    "\n",
    "user_train = data_train.user\n",
    "track_train = data_train.track\n",
    "y_train = data_train.y\n",
    "\n",
    "user_test = data_test.user\n",
    "track_test = data_test.track\n",
    "y_test = data_test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameter range\n",
    "latent_dims = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80, 100]\n",
    "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "epochss = [3, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Latent Dimension Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 2s 22us/step - loss: 0.6928 - acc: 0.5133 - val_loss: 0.6918 - val_acc: 0.5376\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 2s 21us/step - loss: 0.6885 - acc: 0.5846 - val_loss: 0.6888 - val_acc: 0.5619\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 2s 21us/step - loss: 0.6795 - acc: 0.6462 - val_loss: 0.6844 - val_acc: 0.5702\n",
      "130686/130686 [==============================] - 4s 32us/step\n",
      "200/200 [==============================] - 0s 74us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 3s 26us/step - loss: 0.6922 - acc: 0.5174 - val_loss: 0.6905 - val_acc: 0.5374\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 3s 25us/step - loss: 0.6824 - acc: 0.6081 - val_loss: 0.6847 - val_acc: 0.5613\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 2s 22us/step - loss: 0.6646 - acc: 0.6738 - val_loss: 0.6780 - val_acc: 0.5694\n",
      "130686/130686 [==============================] - 4s 31us/step\n",
      "200/200 [==============================] - 0s 53us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 3s 27us/step - loss: 0.6922 - acc: 0.5173 - val_loss: 0.6902 - val_acc: 0.5419\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 2s 22us/step - loss: 0.6813 - acc: 0.6151 - val_loss: 0.6828 - val_acc: 0.5687\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 2s 22us/step - loss: 0.6583 - acc: 0.6844 - val_loss: 0.6743 - val_acc: 0.5791\n",
      "130686/130686 [==============================] - 4s 30us/step\n",
      "200/200 [==============================] - 0s 55us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 3s 25us/step - loss: 0.6919 - acc: 0.5207 - val_loss: 0.6892 - val_acc: 0.5572\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 2s 23us/step - loss: 0.6775 - acc: 0.6285 - val_loss: 0.6801 - val_acc: 0.5779\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 2s 23us/step - loss: 0.6490 - acc: 0.6913 - val_loss: 0.6716 - val_acc: 0.5825\n",
      "130686/130686 [==============================] - 4s 32us/step\n",
      "200/200 [==============================] - 0s 60us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 3s 30us/step - loss: 0.6919 - acc: 0.5226 - val_loss: 0.6892 - val_acc: 0.5572\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 3s 26us/step - loss: 0.6767 - acc: 0.6341 - val_loss: 0.6788 - val_acc: 0.5758\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 3s 26us/step - loss: 0.6441 - acc: 0.6972 - val_loss: 0.6701 - val_acc: 0.5829\n",
      "130686/130686 [==============================] - 4s 32us/step\n",
      "200/200 [==============================] - 0s 55us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 44us/step - loss: 0.6911 - acc: 0.5243 - val_loss: 0.6867 - val_acc: 0.5711\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.6656 - acc: 0.6518 - val_loss: 0.6719 - val_acc: 0.5793\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.6171 - acc: 0.7051 - val_loss: 0.6714 - val_acc: 0.5846\n",
      "130686/130686 [==============================] - 4s 32us/step\n",
      "200/200 [==============================] - 0s 60us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 6s 55us/step - loss: 0.6905 - acc: 0.5296 - val_loss: 0.6852 - val_acc: 0.5624\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 5s 52us/step - loss: 0.6580 - acc: 0.6593 - val_loss: 0.6686 - val_acc: 0.5774\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 5s 51us/step - loss: 0.6007 - acc: 0.7075 - val_loss: 0.6800 - val_acc: 0.5804\n",
      "130686/130686 [==============================] - 4s 32us/step\n",
      "200/200 [==============================] - 0s 73us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 7s 65us/step - loss: 0.6896 - acc: 0.5350 - val_loss: 0.6829 - val_acc: 0.5637\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 6s 61us/step - loss: 0.6498 - acc: 0.6644 - val_loss: 0.6684 - val_acc: 0.5751\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 6s 62us/step - loss: 0.5887 - acc: 0.7093 - val_loss: 0.6944 - val_acc: 0.5782\n",
      "130686/130686 [==============================] - 4s 33us/step\n",
      "200/200 [==============================] - 0s 58us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 8s 77us/step - loss: 0.6892 - acc: 0.5338 - val_loss: 0.6814 - val_acc: 0.5707\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 7s 71us/step - loss: 0.6441 - acc: 0.6669 - val_loss: 0.6681 - val_acc: 0.5819\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 7s 72us/step - loss: 0.5814 - acc: 0.7104 - val_loss: 0.7035 - val_acc: 0.5823\n",
      "130686/130686 [==============================] - 5s 37us/step\n",
      "200/200 [==============================] - 0s 341us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 9s 90us/step - loss: 0.6898 - acc: 0.5339 - val_loss: 0.6819 - val_acc: 0.5630\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 9s 85us/step - loss: 0.6424 - acc: 0.6656 - val_loss: 0.6680 - val_acc: 0.5768\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 9s 85us/step - loss: 0.5764 - acc: 0.7108 - val_loss: 0.7114 - val_acc: 0.5789\n",
      "130686/130686 [==============================] - 5s 35us/step\n",
      "200/200 [==============================] - 0s 66us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 11s 101us/step - loss: 0.6888 - acc: 0.5332 - val_loss: 0.6795 - val_acc: 0.5732\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 10s 97us/step - loss: 0.6369 - acc: 0.6702 - val_loss: 0.6712 - val_acc: 0.5789\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 11s 103us/step - loss: 0.5732 - acc: 0.7109 - val_loss: 0.7222 - val_acc: 0.5792\n",
      "130686/130686 [==============================] - 5s 35us/step\n",
      "200/200 [==============================] - 0s 55us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 12s 114us/step - loss: 0.6884 - acc: 0.5355 - val_loss: 0.6787 - val_acc: 0.5709\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 11s 108us/step - loss: 0.6338 - acc: 0.6706 - val_loss: 0.6738 - val_acc: 0.5790\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 11s 109us/step - loss: 0.5704 - acc: 0.7119 - val_loss: 0.7306 - val_acc: 0.5795\n",
      "130686/130686 [==============================] - 5s 35us/step\n",
      "200/200 [==============================] - 0s 66us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 15s 141us/step - loss: 0.6877 - acc: 0.5368 - val_loss: 0.6769 - val_acc: 0.5716\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 14s 134us/step - loss: 0.6281 - acc: 0.6716 - val_loss: 0.6794 - val_acc: 0.5763\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 14s 133us/step - loss: 0.5666 - acc: 0.7115 - val_loss: 0.7429 - val_acc: 0.5755\n",
      "130686/130686 [==============================] - 5s 36us/step\n",
      "200/200 [==============================] - 0s 72us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 17s 161us/step - loss: 0.6872 - acc: 0.5362 - val_loss: 0.6753 - val_acc: 0.5706\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 16s 155us/step - loss: 0.6241 - acc: 0.6734 - val_loss: 0.6830 - val_acc: 0.5776\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 16s 153us/step - loss: 0.5649 - acc: 0.7115 - val_loss: 0.7479 - val_acc: 0.5761\n",
      "130686/130686 [==============================] - 5s 36us/step\n",
      "200/200 [==============================] - 0s 63us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104548/104548 [==============================] - 19s 178us/step - loss: 0.6868 - acc: 0.5383 - val_loss: 0.6740 - val_acc: 0.5755\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 18s 170us/step - loss: 0.6214 - acc: 0.6744 - val_loss: 0.6872 - val_acc: 0.5800\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 18s 172us/step - loss: 0.5632 - acc: 0.7122 - val_loss: 0.7538 - val_acc: 0.5786\n",
      "130686/130686 [==============================] - 5s 35us/step\n",
      "200/200 [==============================] - 0s 70us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 21s 197us/step - loss: 0.6864 - acc: 0.5379 - val_loss: 0.6733 - val_acc: 0.5725\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 20s 190us/step - loss: 0.6191 - acc: 0.6729 - val_loss: 0.6904 - val_acc: 0.5792\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 20s 191us/step - loss: 0.5621 - acc: 0.7118 - val_loss: 0.7583 - val_acc: 0.5780\n",
      "130686/130686 [==============================] - 5s 35us/step\n",
      "200/200 [==============================] - 0s 60us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 25s 242us/step - loss: 0.6857 - acc: 0.5380 - val_loss: 0.6714 - val_acc: 0.5789\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 25s 237us/step - loss: 0.6156 - acc: 0.6754 - val_loss: 0.6957 - val_acc: 0.5782\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 24s 234us/step - loss: 0.5610 - acc: 0.7106 - val_loss: 0.7620 - val_acc: 0.5795\n",
      "130686/130686 [==============================] - 5s 37us/step\n",
      "200/200 [==============================] - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "learning_rate = learning_rates[1]\n",
    "epochs = epochss[0]\n",
    "latent_dim_list, train_score_list, test_score_list = [], [], []\n",
    "for latent_dim in latent_dims:\n",
    "    NNmodel = build_model(num_user, num_track, latent_dim)\n",
    "    NNmodel.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    NNmodel.fit([np.array(user_train), np.array(track_train)], np.array(y_train), epochs=epochs, batch_size=200, validation_split = .2)\n",
    "    NN_train_score = NNmodel.evaluate([np.array(user_train), np.array(track_train)], np.array(y_train))[1]\n",
    "    NN_test_score = NNmodel.evaluate([np.array(user_test), np.array(track_test)], np.array(y_test))[1]\n",
    "    latent_dim_list.append(latent_dim)\n",
    "    train_score_list.append(NN_train_score)\n",
    "    test_score_list.append(NN_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(latent_dim_list, train_score_list, test_score_list, 'Latent Dimemsion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the dimension doesn't affect the result since the plot is very random. And according to previous paper, we select the dimension of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Learning Rage Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 6s 55us/step - loss: 0.6931 - acc: 0.5033 - val_loss: 0.6926 - val_acc: 0.5144\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 5s 48us/step - loss: 0.6911 - acc: 0.5441 - val_loss: 0.6916 - val_acc: 0.5291\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 5s 45us/step - loss: 0.6880 - acc: 0.5897 - val_loss: 0.6901 - val_acc: 0.5432\n",
      "130686/130686 [==============================] - 5s 42us/step\n",
      "200/200 [==============================] - 0s 70us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 48us/step - loss: 0.6913 - acc: 0.5269 - val_loss: 0.6871 - val_acc: 0.5657\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 40us/step - loss: 0.6664 - acc: 0.6506 - val_loss: 0.6718 - val_acc: 0.5768\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.6173 - acc: 0.7059 - val_loss: 0.6714 - val_acc: 0.5792\n",
      "130686/130686 [==============================] - 5s 39us/step\n",
      "200/200 [==============================] - 0s 81us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 50us/step - loss: 0.6876 - acc: 0.5391 - val_loss: 0.6751 - val_acc: 0.5827\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 40us/step - loss: 0.6257 - acc: 0.6711 - val_loss: 0.6787 - val_acc: 0.5808\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5655 - acc: 0.7114 - val_loss: 0.7404 - val_acc: 0.5825\n",
      "130686/130686 [==============================] - 5s 38us/step\n",
      "200/200 [==============================] - 0s 72us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 50us/step - loss: 0.6783 - acc: 0.5528 - val_loss: 0.6667 - val_acc: 0.5874\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.6002 - acc: 0.6758 - val_loss: 0.7057 - val_acc: 0.5815\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5607 - acc: 0.7029 - val_loss: 0.7518 - val_acc: 0.5843\n",
      "130686/130686 [==============================] - 5s 39us/step\n",
      "200/200 [==============================] - 0s 73us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 51us/step - loss: 0.6789 - acc: 0.5524 - val_loss: 0.6657 - val_acc: 0.5923\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5997 - acc: 0.6752 - val_loss: 0.7013 - val_acc: 0.5828\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5595 - acc: 0.7044 - val_loss: 0.7437 - val_acc: 0.5844\n",
      "130686/130686 [==============================] - 5s 39us/step\n",
      "200/200 [==============================] - 0s 69us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 50us/step - loss: 0.6810 - acc: 0.5536 - val_loss: 0.6720 - val_acc: 0.5644\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.6068 - acc: 0.6673 - val_loss: 0.7087 - val_acc: 0.5720\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5710 - acc: 0.6969 - val_loss: 0.7331 - val_acc: 0.5671\n",
      "130686/130686 [==============================] - 5s 39us/step\n",
      "200/200 [==============================] - 0s 82us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 51us/step - loss: 0.6944 - acc: 0.5375 - val_loss: 0.6750 - val_acc: 0.5559\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 38us/step - loss: 0.6318 - acc: 0.6491 - val_loss: 0.7451 - val_acc: 0.5575\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 40us/step - loss: 0.5890 - acc: 0.6859 - val_loss: 0.7580 - val_acc: 0.5611\n",
      "130686/130686 [==============================] - 5s 40us/step\n",
      "200/200 [==============================] - 0s 71us/step\n",
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/3\n",
      "104548/104548 [==============================] - 5s 52us/step - loss: 0.9678 - acc: 0.5087 - val_loss: 1.1785 - val_acc: 0.5238\n",
      "Epoch 2/3\n",
      "104548/104548 [==============================] - 4s 40us/step - loss: 1.0751 - acc: 0.5488 - val_loss: 1.1768 - val_acc: 0.5383\n",
      "Epoch 3/3\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 1.1703 - acc: 0.5837 - val_loss: 1.0787 - val_acc: 0.5439\n",
      "130686/130686 [==============================] - 6s 46us/step\n",
      "200/200 [==============================] - 0s 79us/step\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "epochs = epochss[0]\n",
    "learning_rate_list, train_score_list, test_score_list = [], [], []\n",
    "for learning_rate in learning_rates:\n",
    "    NNmodel = build_model(num_user, num_track, latent_dim)\n",
    "    NNmodel.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    NNmodel.fit([np.array(user_train), np.array(track_train)], np.array(y_train), epochs=epochs, batch_size=200, validation_split = .2)\n",
    "    NN_train_score = NNmodel.evaluate([np.array(user_train), np.array(track_train)], np.array(y_train))[1]\n",
    "    NN_test_score = NNmodel.evaluate([np.array(user_test), np.array(track_test)], np.array(y_test))[1]\n",
    "    learning_rate_list.append(learning_rate)\n",
    "    train_score_list.append(NN_train_score)\n",
    "    test_score_list.append(NN_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(learning_rate_list, train_score_list, test_score_list, 'Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate of 0.001 looks the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epochs Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104548 samples, validate on 26138 samples\n",
      "Epoch 1/20\n",
      "104548/104548 [==============================] - 5s 52us/step - loss: 0.6876 - acc: 0.5389 - val_loss: 0.6748 - val_acc: 0.5799\n",
      "Epoch 2/20\n",
      "104548/104548 [==============================] - 5s 45us/step - loss: 0.6253 - acc: 0.6726 - val_loss: 0.6785 - val_acc: 0.5818\n",
      "Epoch 3/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.5654 - acc: 0.7113 - val_loss: 0.7411 - val_acc: 0.5808\n",
      "Epoch 4/20\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5404 - acc: 0.7251 - val_loss: 0.8010 - val_acc: 0.5802\n",
      "Epoch 5/20\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5278 - acc: 0.7309 - val_loss: 0.8491 - val_acc: 0.5803\n",
      "Epoch 6/20\n",
      "104548/104548 [==============================] - 5s 45us/step - loss: 0.5199 - acc: 0.7353 - val_loss: 0.8883 - val_acc: 0.5793\n",
      "Epoch 7/20\n",
      "104548/104548 [==============================] - 4s 41us/step - loss: 0.5148 - acc: 0.7373 - val_loss: 0.9216 - val_acc: 0.5798\n",
      "Epoch 8/20\n",
      "104548/104548 [==============================] - 5s 43us/step - loss: 0.5110 - acc: 0.7393 - val_loss: 0.9558 - val_acc: 0.5822\n",
      "Epoch 9/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.5080 - acc: 0.7398 - val_loss: 0.9850 - val_acc: 0.5818\n",
      "Epoch 10/20\n",
      "104548/104548 [==============================] - 5s 43us/step - loss: 0.5057 - acc: 0.7415 - val_loss: 1.0087 - val_acc: 0.5828\n",
      "Epoch 11/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.5037 - acc: 0.7419 - val_loss: 1.0339 - val_acc: 0.5818\n",
      "Epoch 12/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.5020 - acc: 0.7423 - val_loss: 1.0520 - val_acc: 0.5826\n",
      "Epoch 13/20\n",
      "104548/104548 [==============================] - 4s 43us/step - loss: 0.5005 - acc: 0.7432 - val_loss: 1.0797 - val_acc: 0.5821\n",
      "Epoch 14/20\n",
      "104548/104548 [==============================] - 4s 43us/step - loss: 0.4993 - acc: 0.7429 - val_loss: 1.0998 - val_acc: 0.5827\n",
      "Epoch 15/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.4981 - acc: 0.7436 - val_loss: 1.1198 - val_acc: 0.5817\n",
      "Epoch 16/20\n",
      "104548/104548 [==============================] - 4s 43us/step - loss: 0.4970 - acc: 0.7450 - val_loss: 1.1473 - val_acc: 0.5811\n",
      "Epoch 17/20\n",
      "104548/104548 [==============================] - 4s 42us/step - loss: 0.4961 - acc: 0.7456 - val_loss: 1.1679 - val_acc: 0.5818\n",
      "Epoch 18/20\n",
      "104548/104548 [==============================] - 4s 43us/step - loss: 0.4952 - acc: 0.7452 - val_loss: 1.1830 - val_acc: 0.5823\n",
      "Epoch 19/20\n",
      "104548/104548 [==============================] - 5s 43us/step - loss: 0.4944 - acc: 0.7460 - val_loss: 1.2040 - val_acc: 0.5819\n",
      "Epoch 20/20\n",
      "104548/104548 [==============================] - 4s 43us/step - loss: 0.4936 - acc: 0.7465 - val_loss: 1.2211 - val_acc: 0.5816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3cb97eb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "NNmodel = build_model(num_user, num_track, latent_dim)\n",
    "NNmodel.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NNmodel.fit([np.array(user_train), np.array(track_train)], np.array(y_train), epochs=epochs, batch_size=200, validation_split = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result does not improve much around epochs 5 and hence we choose epochs 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create The Final Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the optimal parameter and train the final model\n",
    "latent_dim = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get matrix of the full dataset\n",
    "no_interaction = 1\n",
    "num_user, num_track, matrix = get_matrix(data_full, no_interaction)\n",
    "user, track, y = get_features(matrix)\n",
    "data_nn = pd.DataFrame(user, columns=['user'])\n",
    "data_nn['track'] = track\n",
    "data_nn['y'] = y\n",
    "\n",
    "#get train and test data\n",
    "data_copy = data_nn.copy()\n",
    "data_test = pd.DataFrame(columns=['user', 'track', 'y'])\n",
    "for n in range(n_playlist*900, n_playlist*1000):\n",
    "    data_hide = data_copy[data_copy.user == n].iloc[0:2]\n",
    "    data_test = data_test.append(data_hide)\n",
    "    \n",
    "data_train = data_copy.drop(data_test.index)\n",
    "\n",
    "user_train = data_train.user\n",
    "track_train = data_train.track\n",
    "y_train = data_train.y\n",
    "\n",
    "user_test = data_test.user\n",
    "track_test = data_test.track\n",
    "y_test = data_test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_train (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "track_train (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_53 (Embedding)        (None, 1, 10)        100000      user_train[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_54 (Embedding)        (None, 1, 10)        1329200     track_train[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 10)           0           embedding_53[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 10)           0           embedding_54[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 10)           0           flatten_53[0][0]                 \n",
      "                                                                 flatten_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            11          add_27[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,429,211\n",
      "Trainable params: 1,429,211\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Build the final model\n",
    "NNmodel = build_model(num_user, num_track, latent_dim)\n",
    "NNmodel.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(NNmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1042625 samples, validate on 260657 samples\n",
      "Epoch 1/5\n",
      "1042625/1042625 [==============================] - 126s 121us/step - loss: 0.5427 - acc: 0.7242 - val_loss: 0.5186 - val_acc: 0.7711\n",
      "Epoch 2/5\n",
      "1042625/1042625 [==============================] - 130s 124us/step - loss: 0.4545 - acc: 0.7924 - val_loss: 0.5388 - val_acc: 0.7666\n",
      "Epoch 3/5\n",
      "1042625/1042625 [==============================] - 124s 119us/step - loss: 0.4383 - acc: 0.8009 - val_loss: 0.5561 - val_acc: 0.7659\n",
      "Epoch 4/5\n",
      "1042625/1042625 [==============================] - 127s 121us/step - loss: 0.4297 - acc: 0.8055 - val_loss: 0.5694 - val_acc: 0.7653\n",
      "Epoch 5/5\n",
      "1042625/1042625 [==============================] - 127s 121us/step - loss: 0.4242 - acc: 0.8078 - val_loss: 0.5773 - val_acc: 0.7644\n",
      "1303282/1303282 [==============================] - 56s 43us/step\n",
      "2000/2000 [==============================] - 0s 48us/step\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "NNmodel.fit([np.array(user_train), np.array(track_train)], np.array(y_train), epochs=epochs, batch_size=200, validation_split = .2)\n",
    "NN_train_score = NNmodel.evaluate([np.array(user_train), np.array(track_train)], np.array(y_train))[1]\n",
    "NN_test_score = NNmodel.evaluate([np.array(user_test), np.array(track_test)], np.array(y_test))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NN train score is 0.81\n",
      "The NN test score is 0.78\n"
     ]
    }
   ],
   "source": [
    "print('The NN train score is {}'.format(round(NN_train_score, 2)))\n",
    "print('The NN test score is {}'.format(round(NN_test_score, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum train score is 0.5\n",
      "The minimum test score is 0.5\n"
     ]
    }
   ],
   "source": [
    "min_train_score = 1 - np.mean(y_train)\n",
    "min_test_score = 1 - np.mean(y_test)\n",
    "print('The minimum train score is {}'.format(round(min_train_score, 2)))\n",
    "print('The minimum test score is {}'.format(round(min_test_score, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result we can see that our model works much better than the minimum score which is 0.5 - 0.5.\n",
    "\n",
    "The test score means that in test set, we successfully predict a large portion of the test tracks for each user in to the right category (with interaction or without interaction. The result means that, given a user and a track, we can define if the user and the track has possible interactions. It is logically very useful in generating a recommendation list: we can take the top 100 tracks with highest probability of interaction from our full unique tracks dataset as the recommendation list.\n",
    "\n",
    "In the follwoing section of combined model, we will apply this idea to generate our final recommendation list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Model: Generating Recommendation List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did before, we will hide one track in each playlist(user) and generate a recommendation list, see if this recommendation list contain that hidden track. However, due to our limitation of training data size and the very large tracks in the the music bank, we don't expect that for a large percent of time, we can successfully find out that exact one hidden track. In real world, the user preference can be much broader than just one \"hidden\" track.\n",
    "\n",
    "We choose to combine the baseline model and Neural Network model together to generate the list. First, we will extract our previous recommendation list (including the not overlap tracks of top 5 similar playlists in baseline model). Instead of randomly select 100 of them as recommendation, we apply the trained Artifical Neural Network to rank the possible interactions and select the top 100 tracks with the highest interaction score and use them as our final recommendation list.\n",
    "\n",
    "As far as our prediction score increase (higher than what we get in baseline model), our neural network works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom_list_combine = recommendation_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_scores = np.zeros(len(track_hide))\n",
    "for x in range(len(track_hide)):\n",
    "    track_full_list = list(set(recom_list_combine[x]))\n",
    "    existing_track = data_train[data_train['user'] == x].track\n",
    "    hidden_track = list(track_test)[x*2]\n",
    "    predict_track = list(Counter(track_full_list)-Counter(existing_track))\n",
    "    predict_user = np.zeros(len(predict_track))+x\n",
    "    \n",
    "    s = NNmodel.predict([np.array(x).reshape(-1,1), np.array(hidden_track).reshape(-1,1)])\n",
    "    #print('score is {}'.format(s))\n",
    "    \n",
    "    predictions = np.transpose(NNmodel.predict([predict_user, np.array(predict_track)]))[0]\n",
    "    index = np.argsort(predictions)[-no_recommendation:]\n",
    "\n",
    "    recommendation_list_ann = np.array(predict_track)[index]\n",
    "    \n",
    "    if hidden_track in recommendation_list_ann:\n",
    "        recommendation_scores[x] = 1\n",
    "        \n",
    "total_score = np.average(recommendation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 24.0 percent of time, we successfully include the hidden track\n"
     ]
    }
   ],
   "source": [
    "print('For {} percent of time, we successfully include the hidden track'.format(round(total_score*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as what we have expected, even thouth the predction accuracy of neural network is very high, the probability that the recommendation list we generate that will include the hidden track is very low because:\n",
    "\n",
    " - The hidden track is not the exact indicator of \"user preference\" because the user may have higher probability to like the other traks that does not neccessarily to be the hidden track! Hence the real \"user preference\" for the not hidden track in other playlist will be higher than the actual \"hidden track\" that we hided before. But in the scope of this project, we are not able to find out the true user preference and hence, we can just use the \"hidden track\" as a possible indicator.\n",
    " \n",
    "Therefore, even though our score is not very high, it did improve a lot comparing to our baseline model, which is basically in random basesa. This is consistant with our high neural network prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415.3134542769985\n"
     ]
    }
   ],
   "source": [
    "#calculate the running time of whole script\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
